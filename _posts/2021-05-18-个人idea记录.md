---
layout: mypost
title: 个人 Idea 记录
categories: [idea, 深度学习]

---

## 个人 Idea 记录

### 2021.05.18

**对比学习（Contrastive Learning）和 局部敏感哈希（LSH）之间的关系**

对比学习的基本思想是：学习一个映射函数 $f$ ，把样本 $x$ 编码成其表示 $f(x)$，对比学习的核心就是使得这个 $f$ 满足下面这个式子：$s\left(f(x), f\left(x^{+}\right)\right)>>s\left(f(x), f\left(x^{-}\right)\right)$。这里 $x^+$ 就是和 $x$ 类似的样本，$x^-$ 就是和 $x$ 不相似的样本，$s(·,·)$ 是一个度量样本之间相似程度的函数，一个比较典型的 score 函数就是就是向量内积，即优化下面这一期望：

![function](function.png)

![Contrastive Learning](ContrastiveLearning.jpeg)



LSH的基本思想是：将原始数据空间中的两个相邻数据点通过相同的映射或投影变换（projection）后，这两个数据点在新的数据空间中仍然相邻的概率很大，而不相邻的数据点被映射到同一个桶的概率很小。

**所以说对比学习和局部敏感hash的本质是一样的。**

LSH 有一个性质如下图，随机投影函数是LSH，考虑 $w$ 为 1，k个随机投影，这不就是个全连接层嘛，不过每一个小的bias不一样而已！！！

**所以说全联接层可以学LSH** ---- 当前最火的就是 MLP！！

**初始化全联接层参数为高斯参数，然后一层一层预训练对比学习，再累加起来微调！**

![LSH](LSH.png)

